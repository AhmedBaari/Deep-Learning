{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23404,"sourceType":"datasetVersion","datasetId":17860}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:00.246916Z","iopub.execute_input":"2024-09-05T13:09:00.247390Z","iopub.status.idle":"2024-09-05T13:09:00.736299Z","shell.execute_reply.started":"2024-09-05T13:09:00.247345Z","shell.execute_reply":"2024-09-05T13:09:00.735025Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/iris-flower-dataset/IRIS.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:00.738191Z","iopub.execute_input":"2024-09-05T13:09:00.738750Z","iopub.status.idle":"2024-09-05T13:09:00.762492Z","shell.execute_reply.started":"2024-09-05T13:09:00.738705Z","shell.execute_reply":"2024-09-05T13:09:00.760803Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:00.889639Z","iopub.execute_input":"2024-09-05T13:09:00.890100Z","iopub.status.idle":"2024-09-05T13:09:00.921730Z","shell.execute_reply.started":"2024-09-05T13:09:00.890056Z","shell.execute_reply":"2024-09-05T13:09:00.920303Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   sepal_length  sepal_width  petal_length  petal_width      species\n0           5.1          3.5           1.4          0.2  Iris-setosa\n1           4.9          3.0           1.4          0.2  Iris-setosa\n2           4.7          3.2           1.3          0.2  Iris-setosa\n3           4.6          3.1           1.5          0.2  Iris-setosa\n4           5.0          3.6           1.4          0.2  Iris-setosa","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['species'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:01.874462Z","iopub.execute_input":"2024-09-05T13:09:01.874923Z","iopub.status.idle":"2024-09-05T13:09:01.886785Z","shell.execute_reply.started":"2024-09-05T13:09:01.874879Z","shell.execute_reply":"2024-09-05T13:09:01.885588Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df['species'].replace({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:02.619906Z","iopub.execute_input":"2024-09-05T13:09:02.620375Z","iopub.status.idle":"2024-09-05T13:09:02.629181Z","shell.execute_reply.started":"2024-09-05T13:09:02.620331Z","shell.execute_reply":"2024-09-05T13:09:02.627769Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2485095.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['species'].replace({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}, inplace=True)\n/tmp/ipykernel_36/2485095.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df['species'].replace({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}, inplace=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess(x,y):\n    enc = OneHotEncoder()\n    y_out = enc.fit_transform(y.values.reshape(-1,1))\n    scaler = StandardScaler()\n    x_out = scaler.fit_transform(x)\n    return x_out,y_out.toarray()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:03.414045Z","iopub.execute_input":"2024-09-05T13:09:03.415621Z","iopub.status.idle":"2024-09-05T13:09:03.422479Z","shell.execute_reply.started":"2024-09-05T13:09:03.415555Z","shell.execute_reply":"2024-09-05T13:09:03.420497Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:05.939730Z","iopub.execute_input":"2024-09-05T13:09:05.940226Z","iopub.status.idle":"2024-09-05T13:09:06.665392Z","shell.execute_reply.started":"2024-09-05T13:09:05.940139Z","shell.execute_reply":"2024-09-05T13:09:06.663989Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:15.724742Z","iopub.execute_input":"2024-09-05T13:09:15.725164Z","iopub.status.idle":"2024-09-05T13:09:15.744434Z","shell.execute_reply.started":"2024-09-05T13:09:15.725124Z","shell.execute_reply":"2024-09-05T13:09:15.743002Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(df.drop([\"species\"],axis=1),df[\"species\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:17.320585Z","iopub.execute_input":"2024-09-05T13:09:17.321050Z","iopub.status.idle":"2024-09-05T13:09:17.336531Z","shell.execute_reply.started":"2024-09-05T13:09:17.321005Z","shell.execute_reply":"2024-09-05T13:09:17.334931Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:28.575685Z","iopub.execute_input":"2024-09-05T13:09:28.576185Z","iopub.status.idle":"2024-09-05T13:09:28.585009Z","shell.execute_reply.started":"2024-09-05T13:09:28.576138Z","shell.execute_reply":"2024-09-05T13:09:28.583724Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"((112, 4), (38, 4))"},"metadata":{}}]},{"cell_type":"code","source":"xin,yin = preprocess(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:28.959463Z","iopub.execute_input":"2024-09-05T13:09:28.960655Z","iopub.status.idle":"2024-09-05T13:09:28.980361Z","shell.execute_reply.started":"2024-09-05T13:09:28.960601Z","shell.execute_reply":"2024-09-05T13:09:28.978914Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:29.915692Z","iopub.execute_input":"2024-09-05T13:09:29.916167Z","iopub.status.idle":"2024-09-05T13:09:29.924880Z","shell.execute_reply.started":"2024-09-05T13:09:29.916120Z","shell.execute_reply":"2024-09-05T13:09:29.923608Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"122    2\n79     1\n63     1\n89     1\n6      0\nName: species, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"device = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:39.904895Z","iopub.execute_input":"2024-09-05T13:09:39.905611Z","iopub.status.idle":"2024-09-05T13:09:39.912719Z","shell.execute_reply.started":"2024-09-05T13:09:39.905560Z","shell.execute_reply":"2024-09-05T13:09:39.911487Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Using cpu device\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchmetrics\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:41.600027Z","iopub.execute_input":"2024-09-05T13:09:41.600498Z","iopub.status.idle":"2024-09-05T13:09:41.606308Z","shell.execute_reply.started":"2024-09-05T13:09:41.600453Z","shell.execute_reply":"2024-09-05T13:09:41.604897Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class ClassificationModel(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear_relu_stack = torch.nn.Sequential(\n            torch.nn.Linear(4, 3),\n            torch.nn.Softmax(dim=1)\n        )\n\n    def forward(self, x):\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = ClassificationModel().to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:42.610048Z","iopub.execute_input":"2024-09-05T13:09:42.610506Z","iopub.status.idle":"2024-09-05T13:09:42.658815Z","shell.execute_reply.started":"2024-09-05T13:09:42.610465Z","shell.execute_reply":"2024-09-05T13:09:42.657429Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"ClassificationModel(\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=4, out_features=3, bias=True)\n    (1): Softmax(dim=1)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"xt,yt = preprocess(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:43.569652Z","iopub.execute_input":"2024-09-05T13:09:43.570145Z","iopub.status.idle":"2024-09-05T13:09:43.580885Z","shell.execute_reply.started":"2024-09-05T13:09:43.570098Z","shell.execute_reply":"2024-09-05T13:09:43.579444Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"loss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:45.969408Z","iopub.execute_input":"2024-09-05T13:09:45.969899Z","iopub.status.idle":"2024-09-05T13:09:47.296300Z","shell.execute_reply.started":"2024-09-05T13:09:45.969843Z","shell.execute_reply":"2024-09-05T13:09:47.295071Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train(model,epoch,loss_fn, optimizer,xin,yin):\n    model.train()\n    p = np.random.permutation(len(xin))\n    tempx = xin[p]\n    tempy = yin[p]\n    pred = model(torch.from_numpy(tempx).to(torch.float32))\n    loss = loss_fn(pred, torch.from_numpy(tempy).to(torch.float32))\n\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n    loss, current = loss.item(), epoch\n    print(f\"loss: {loss:>7f}  [{current:>5d}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:48.389528Z","iopub.execute_input":"2024-09-05T13:09:48.390329Z","iopub.status.idle":"2024-09-05T13:09:48.398445Z","shell.execute_reply.started":"2024-09-05T13:09:48.390267Z","shell.execute_reply":"2024-09-05T13:09:48.397300Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def test(model, loss_fn,xt,yt):\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        X, y = torch.from_numpy(xt).to(torch.float32), torch.from_numpy(yt).to(torch.float32)\n        pred = model(X)\n        test_loss += loss_fn(pred, y).item()\n    print(f\"Test Error: Avg loss: {test_loss:>8f} \\n\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:49.899132Z","iopub.execute_input":"2024-09-05T13:09:49.899593Z","iopub.status.idle":"2024-09-05T13:09:49.907909Z","shell.execute_reply.started":"2024-09-05T13:09:49.899552Z","shell.execute_reply":"2024-09-05T13:09:49.906256Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"epochs = 100\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(model,t, loss_fn, optimizer,xin,yin)\n    test(model, loss_fn,xt,yt)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:51.029249Z","iopub.execute_input":"2024-09-05T13:09:51.030374Z","iopub.status.idle":"2024-09-05T13:09:51.293496Z","shell.execute_reply.started":"2024-09-05T13:09:51.030323Z","shell.execute_reply":"2024-09-05T13:09:51.292165Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\nloss: 1.224760  [    0\nTest Error: Avg loss: 1.159721 \n\nEpoch 2\n-------------------------------\nloss: 1.158162  [    1\nTest Error: Avg loss: 1.098863 \n\nEpoch 3\n-------------------------------\nloss: 1.092422  [    2\nTest Error: Avg loss: 1.036591 \n\nEpoch 4\n-------------------------------\nloss: 1.028641  [    3\nTest Error: Avg loss: 0.970120 \n\nEpoch 5\n-------------------------------\nloss: 0.962573  [    4\nTest Error: Avg loss: 0.900195 \n\nEpoch 6\n-------------------------------\nloss: 0.893138  [    5\nTest Error: Avg loss: 0.841619 \n\nEpoch 7\n-------------------------------\nloss: 0.832268  [    6\nTest Error: Avg loss: 0.804467 \n\nEpoch 8\n-------------------------------\nloss: 0.791179  [    7\nTest Error: Avg loss: 0.783614 \n\nEpoch 9\n-------------------------------\nloss: 0.767783  [    8\nTest Error: Avg loss: 0.770918 \n\nEpoch 10\n-------------------------------\nloss: 0.753491  [    9\nTest Error: Avg loss: 0.762227 \n\nEpoch 11\n-------------------------------\nloss: 0.743156  [   10\nTest Error: Avg loss: 0.755821 \n\nEpoch 12\n-------------------------------\nloss: 0.734866  [   11\nTest Error: Avg loss: 0.750809 \n\nEpoch 13\n-------------------------------\nloss: 0.727859  [   12\nTest Error: Avg loss: 0.746636 \n\nEpoch 14\n-------------------------------\nloss: 0.721734  [   13\nTest Error: Avg loss: 0.742946 \n\nEpoch 15\n-------------------------------\nloss: 0.716242  [   14\nTest Error: Avg loss: 0.739519 \n\nEpoch 16\n-------------------------------\nloss: 0.711220  [   15\nTest Error: Avg loss: 0.736219 \n\nEpoch 17\n-------------------------------\nloss: 0.706562  [   16\nTest Error: Avg loss: 0.732963 \n\nEpoch 18\n-------------------------------\nloss: 0.702196  [   17\nTest Error: Avg loss: 0.729698 \n\nEpoch 19\n-------------------------------\nloss: 0.698068  [   18\nTest Error: Avg loss: 0.726389 \n\nEpoch 20\n-------------------------------\nloss: 0.694138  [   19\nTest Error: Avg loss: 0.723006 \n\nEpoch 21\n-------------------------------\nloss: 0.690369  [   20\nTest Error: Avg loss: 0.719526 \n\nEpoch 22\n-------------------------------\nloss: 0.686728  [   21\nTest Error: Avg loss: 0.715925 \n\nEpoch 23\n-------------------------------\nloss: 0.683183  [   22\nTest Error: Avg loss: 0.712186 \n\nEpoch 24\n-------------------------------\nloss: 0.679708  [   23\nTest Error: Avg loss: 0.708290 \n\nEpoch 25\n-------------------------------\nloss: 0.676276  [   24\nTest Error: Avg loss: 0.704227 \n\nEpoch 26\n-------------------------------\nloss: 0.672870  [   25\nTest Error: Avg loss: 0.699990 \n\nEpoch 27\n-------------------------------\nloss: 0.669474  [   26\nTest Error: Avg loss: 0.695583 \n\nEpoch 28\n-------------------------------\nloss: 0.666083  [   27\nTest Error: Avg loss: 0.691022 \n\nEpoch 29\n-------------------------------\nloss: 0.662695  [   28\nTest Error: Avg loss: 0.686337 \n\nEpoch 30\n-------------------------------\nloss: 0.659317  [   29\nTest Error: Avg loss: 0.681571 \n\nEpoch 31\n-------------------------------\nloss: 0.655959  [   30\nTest Error: Avg loss: 0.676785 \n\nEpoch 32\n-------------------------------\nloss: 0.652640  [   31\nTest Error: Avg loss: 0.672047 \n\nEpoch 33\n-------------------------------\nloss: 0.649378  [   32\nTest Error: Avg loss: 0.667431 \n\nEpoch 34\n-------------------------------\nloss: 0.646197  [   33\nTest Error: Avg loss: 0.663009 \n\nEpoch 35\n-------------------------------\nloss: 0.643120  [   34\nTest Error: Avg loss: 0.658847 \n\nEpoch 36\n-------------------------------\nloss: 0.640174  [   35\nTest Error: Avg loss: 0.655000 \n\nEpoch 37\n-------------------------------\nloss: 0.637388  [   36\nTest Error: Avg loss: 0.651511 \n\nEpoch 38\n-------------------------------\nloss: 0.634791  [   37\nTest Error: Avg loss: 0.648409 \n\nEpoch 39\n-------------------------------\nloss: 0.632416  [   38\nTest Error: Avg loss: 0.645710 \n\nEpoch 40\n-------------------------------\nloss: 0.630294  [   39\nTest Error: Avg loss: 0.643406 \n\nEpoch 41\n-------------------------------\nloss: 0.628443  [   40\nTest Error: Avg loss: 0.641469 \n\nEpoch 42\n-------------------------------\nloss: 0.626868  [   41\nTest Error: Avg loss: 0.639847 \n\nEpoch 43\n-------------------------------\nloss: 0.625547  [   42\nTest Error: Avg loss: 0.638475 \n\nEpoch 44\n-------------------------------\nloss: 0.624438  [   43\nTest Error: Avg loss: 0.637281 \n\nEpoch 45\n-------------------------------\nloss: 0.623481  [   44\nTest Error: Avg loss: 0.636199 \n\nEpoch 46\n-------------------------------\nloss: 0.622612  [   45\nTest Error: Avg loss: 0.635180 \n\nEpoch 47\n-------------------------------\nloss: 0.621771  [   46\nTest Error: Avg loss: 0.634192 \n\nEpoch 48\n-------------------------------\nloss: 0.620918  [   47\nTest Error: Avg loss: 0.633221 \n\nEpoch 49\n-------------------------------\nloss: 0.620031  [   48\nTest Error: Avg loss: 0.632265 \n\nEpoch 50\n-------------------------------\nloss: 0.619106  [   49\nTest Error: Avg loss: 0.631330 \n\nEpoch 51\n-------------------------------\nloss: 0.618157  [   50\nTest Error: Avg loss: 0.630422 \n\nEpoch 52\n-------------------------------\nloss: 0.617202  [   51\nTest Error: Avg loss: 0.629547 \n\nEpoch 53\n-------------------------------\nloss: 0.616261  [   52\nTest Error: Avg loss: 0.628708 \n\nEpoch 54\n-------------------------------\nloss: 0.615348  [   53\nTest Error: Avg loss: 0.627900 \n\nEpoch 55\n-------------------------------\nloss: 0.614474  [   54\nTest Error: Avg loss: 0.627118 \n\nEpoch 56\n-------------------------------\nloss: 0.613639  [   55\nTest Error: Avg loss: 0.626352 \n\nEpoch 57\n-------------------------------\nloss: 0.612841  [   56\nTest Error: Avg loss: 0.625595 \n\nEpoch 58\n-------------------------------\nloss: 0.612075  [   57\nTest Error: Avg loss: 0.624838 \n\nEpoch 59\n-------------------------------\nloss: 0.611335  [   58\nTest Error: Avg loss: 0.624076 \n\nEpoch 60\n-------------------------------\nloss: 0.610618  [   59\nTest Error: Avg loss: 0.623308 \n\nEpoch 61\n-------------------------------\nloss: 0.609920  [   60\nTest Error: Avg loss: 0.622535 \n\nEpoch 62\n-------------------------------\nloss: 0.609240  [   61\nTest Error: Avg loss: 0.621760 \n\nEpoch 63\n-------------------------------\nloss: 0.608579  [   62\nTest Error: Avg loss: 0.620988 \n\nEpoch 64\n-------------------------------\nloss: 0.607939  [   63\nTest Error: Avg loss: 0.620225 \n\nEpoch 65\n-------------------------------\nloss: 0.607320  [   64\nTest Error: Avg loss: 0.619478 \n\nEpoch 66\n-------------------------------\nloss: 0.606724  [   65\nTest Error: Avg loss: 0.618751 \n\nEpoch 67\n-------------------------------\nloss: 0.606152  [   66\nTest Error: Avg loss: 0.618048 \n\nEpoch 68\n-------------------------------\nloss: 0.605604  [   67\nTest Error: Avg loss: 0.617371 \n\nEpoch 69\n-------------------------------\nloss: 0.605078  [   68\nTest Error: Avg loss: 0.616721 \n\nEpoch 70\n-------------------------------\nloss: 0.604574  [   69\nTest Error: Avg loss: 0.616099 \n\nEpoch 71\n-------------------------------\nloss: 0.604089  [   70\nTest Error: Avg loss: 0.615505 \n\nEpoch 72\n-------------------------------\nloss: 0.603622  [   71\nTest Error: Avg loss: 0.614939 \n\nEpoch 73\n-------------------------------\nloss: 0.603170  [   72\nTest Error: Avg loss: 0.614401 \n\nEpoch 74\n-------------------------------\nloss: 0.602731  [   73\nTest Error: Avg loss: 0.613889 \n\nEpoch 75\n-------------------------------\nloss: 0.602303  [   74\nTest Error: Avg loss: 0.613405 \n\nEpoch 76\n-------------------------------\nloss: 0.601886  [   75\nTest Error: Avg loss: 0.612949 \n\nEpoch 77\n-------------------------------\nloss: 0.601477  [   76\nTest Error: Avg loss: 0.612521 \n\nEpoch 78\n-------------------------------\nloss: 0.601077  [   77\nTest Error: Avg loss: 0.612120 \n\nEpoch 79\n-------------------------------\nloss: 0.600683  [   78\nTest Error: Avg loss: 0.611746 \n\nEpoch 80\n-------------------------------\nloss: 0.600298  [   79\nTest Error: Avg loss: 0.611398 \n\nEpoch 81\n-------------------------------\nloss: 0.599919  [   80\nTest Error: Avg loss: 0.611073 \n\nEpoch 82\n-------------------------------\nloss: 0.599548  [   81\nTest Error: Avg loss: 0.610770 \n\nEpoch 83\n-------------------------------\nloss: 0.599185  [   82\nTest Error: Avg loss: 0.610485 \n\nEpoch 84\n-------------------------------\nloss: 0.598830  [   83\nTest Error: Avg loss: 0.610214 \n\nEpoch 85\n-------------------------------\nloss: 0.598483  [   84\nTest Error: Avg loss: 0.609955 \n\nEpoch 86\n-------------------------------\nloss: 0.598144  [   85\nTest Error: Avg loss: 0.609704 \n\nEpoch 87\n-------------------------------\nloss: 0.597814  [   86\nTest Error: Avg loss: 0.609457 \n\nEpoch 88\n-------------------------------\nloss: 0.597492  [   87\nTest Error: Avg loss: 0.609211 \n\nEpoch 89\n-------------------------------\nloss: 0.597178  [   88\nTest Error: Avg loss: 0.608964 \n\nEpoch 90\n-------------------------------\nloss: 0.596872  [   89\nTest Error: Avg loss: 0.608714 \n\nEpoch 91\n-------------------------------\nloss: 0.596572  [   90\nTest Error: Avg loss: 0.608459 \n\nEpoch 92\n-------------------------------\nloss: 0.596279  [   91\nTest Error: Avg loss: 0.608199 \n\nEpoch 93\n-------------------------------\nloss: 0.595992  [   92\nTest Error: Avg loss: 0.607935 \n\nEpoch 94\n-------------------------------\nloss: 0.595711  [   93\nTest Error: Avg loss: 0.607668 \n\nEpoch 95\n-------------------------------\nloss: 0.595436  [   94\nTest Error: Avg loss: 0.607398 \n\nEpoch 96\n-------------------------------\nloss: 0.595166  [   95\nTest Error: Avg loss: 0.607127 \n\nEpoch 97\n-------------------------------\nloss: 0.594902  [   96\nTest Error: Avg loss: 0.606856 \n\nEpoch 98\n-------------------------------\nloss: 0.594642  [   97\nTest Error: Avg loss: 0.606588 \n\nEpoch 99\n-------------------------------\nloss: 0.594387  [   98\nTest Error: Avg loss: 0.606324 \n\nEpoch 100\n-------------------------------\nloss: 0.594136  [   99\nTest Error: Avg loss: 0.606063 \n\nDone!\n","output_type":"stream"}]},{"cell_type":"code","source":"def print_report(y_true,y_pred):\n    print(classification_report(y_true,y_pred))\n    print(f\"Accuracy:- {accuracy_score(y_true,y_pred)}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:09:59.584854Z","iopub.execute_input":"2024-09-05T13:09:59.585303Z","iopub.status.idle":"2024-09-05T13:09:59.591123Z","shell.execute_reply.started":"2024-09-05T13:09:59.585261Z","shell.execute_reply":"2024-09-05T13:09:59.589670Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    x = torch.from_numpy(xt).to(device).to(torch.float32)\n    pred = model(x)\n    print_report(yt,(pred>0.5))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:10:00.969506Z","iopub.execute_input":"2024-09-05T13:10:00.969976Z","iopub.status.idle":"2024-09-05T13:10:01.000749Z","shell.execute_reply.started":"2024-09-05T13:10:00.969935Z","shell.execute_reply":"2024-09-05T13:10:00.998583Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        13\n           1       1.00      0.92      0.96        13\n           2       0.92      1.00      0.96        12\n\n   micro avg       0.97      0.97      0.97        38\n   macro avg       0.97      0.97      0.97        38\nweighted avg       0.98      0.97      0.97        38\n samples avg       0.97      0.97      0.97        38\n\nAccuracy:- 0.9736842105263158\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}